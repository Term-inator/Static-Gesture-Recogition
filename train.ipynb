{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function _parse_image_function at 0x000001F0DF5DFAE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function _parse_image_function at 0x000001F0DF5DFAE8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Constant'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "{'image_raw': <tf.Tensor 'ParseSingleExample_1/ParseExample/ParseExampleV2:0' shape=() dtype=string>, 'label': <tf.Tensor 'ParseSingleExample_1/ParseExample/ParseExampleV2:1' shape=() dtype=int64>}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: {label: (), image: (640, 240, 3)}, types: {label: tf.int64, image: tf.uint8}>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "raw_image_dataset = tf.data.TFRecordDataset('images.tfrecords')\n",
    "\n",
    "# Create a dictionary describing the features.\n",
    "image_feature_description = {\n",
    "    'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "\n",
    "def _parse_image_function(example_proto):\n",
    "  example = tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "  label, image = example[\"label\"], example[\"image_raw\"]\n",
    "  print(tf.io.parse_single_example(example_proto, image_feature_description))\n",
    "  # image_raw = image_features['image_raw']\n",
    "  image = tf.io.decode_raw(image, tf.uint8)\n",
    "  image = tf.reshape(image, [640, 240, 3])\n",
    "  return {\n",
    "    \"label\": label, \n",
    "    \"image\": image\n",
    "    }\n",
    "  \n",
    "  # return tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "\n",
    "parsed_image_dataset = raw_image_dataset.map(_parse_image_function)\n",
    "parsed_image_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 6  6  6]\n",
      "  [ 5  5  5]\n",
      "  [ 4  4  4]\n",
      "  ...\n",
      "  [ 8  8  8]\n",
      "  [ 9  9  9]\n",
      "  [ 8  8  8]]\n",
      "\n",
      " [[ 8  8  8]\n",
      "  [ 9  9  9]\n",
      "  [10 10 10]\n",
      "  ...\n",
      "  [ 3  3  3]\n",
      "  [ 4  4  4]\n",
      "  [ 3  3  3]]\n",
      "\n",
      " [[ 4  4  4]\n",
      "  [ 5  5  5]\n",
      "  [ 4  4  4]\n",
      "  ...\n",
      "  [ 4  4  4]\n",
      "  [ 4  4  4]\n",
      "  [ 4  4  4]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 8  8  8]\n",
      "  [ 5  5  5]\n",
      "  [ 7  7  7]\n",
      "  ...\n",
      "  [ 7  7  7]\n",
      "  [ 3  3  3]\n",
      "  [ 5  5  5]]\n",
      "\n",
      " [[ 4  4  4]\n",
      "  [ 5  5  5]\n",
      "  [ 2  2  2]\n",
      "  ...\n",
      "  [26 26 26]\n",
      "  [26 26 26]\n",
      "  [25 25 25]]\n",
      "\n",
      " [[25 25 25]\n",
      "  [28 28 28]\n",
      "  [31 31 31]\n",
      "  ...\n",
      "  [25 25 25]\n",
      "  [12 12 12]\n",
      "  [20 20 20]]], shape=(640, 240, 3), dtype=uint8)\n"
     ]
    }
   ],
   "source": [
    "for image_features in parsed_image_dataset:\n",
    "  image = image_features['image']\n",
    "  print(image)\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v2.train' has no attribute 'shuffle_batch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-f05e58e70cb2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"label\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"image\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow._api.v2.train' has no attribute 'shuffle_batch'"
     ]
    }
   ],
   "source": [
    "print(raw_image_dataset[\"image\"])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "919eb0904b72c37e8d6c7e3b2f7b6f162c89cafcc297fba09b2d10c79c52f5eb"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
