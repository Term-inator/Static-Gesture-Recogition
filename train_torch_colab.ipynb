{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":6256,"status":"ok","timestamp":1643165628821,"user":{"displayName":"Bill chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03010122854624571547"},"user_tz":-480},"id":"0wpyJ6Pm5bTI"},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","from torch import nn\n","import torch.nn.functional as F\n","from torchvision import transforms\n","\n","from PIL import Image\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":61,"status":"ok","timestamp":1643165628823,"user":{"displayName":"Bill chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03010122854624571547"},"user_tz":-480},"id":"zcDkHoWYRld-"},"outputs":[],"source":["class Params:\n","  class_num = 10\n","  batch_size = 1\n","  learning_rate = 0.001\n","  dropout = 0.2\n","  momentum = 0.9\n","  epochs = 10\n"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":64,"status":"ok","timestamp":1643165628829,"user":{"displayName":"Bill chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03010122854624571547"},"user_tz":-480},"id":"K9hPcHQZdV_z"},"outputs":[],"source":["base_path = \"../leapGestRecog/\"\n","people = [\"00\", \"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\"]\n","gestures = [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\"]\n","gestures_map = {\n","    1: \"palm\", \n","    2: \"l\", \n","    3: \"fist\", \n","    4: \"fist_moved\",\n","    5: \"thumb\", \n","    6: \"index\", \n","    7: \"ok\", \n","    8: \"palm_moved\", \n","    9: \"c\",\n","    10: \"down\"\n","}\n","\n","class GestureDataset(Dataset):\n","  def __init__(self, transform = None, target_transform = None):\n","    img_labels = []\n","    for person in range(10):\n","      for label in range(1, 11):\n","        path = \"%s/%s_%s/\" % (str(person).zfill(2), str(label).zfill(2), gestures_map[label])\n","        for id in range(1, 201):\n","          filename = \"frame_%s_%s_%s.png\" % (str(person).zfill(2), str(label).zfill(2), str(id).zfill(4))\n","          img_labels.append((base_path + path + filename, label))\n","          \n","    self.img_labels = img_labels \n","    self.transform = transform\n","    self.target_transform = target_transform\n","  def __getitem__(self, index):\n","    path, label = self.img_labels[index]\n","    img = Image.open(path).convert('L') # convert to black and white\n","    if self.transform is not None:\n","      img = self.transform(img)\n","    return img, label - 1\n","  def __len__(self):\n","    return len(self.img_labels)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":67,"status":"ok","timestamp":1643165628834,"user":{"displayName":"Bill chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03010122854624571547"},"user_tz":-480},"id":"EQliUFhZ15iK"},"outputs":[],"source":["gesture_dataset = GestureDataset(transform=transforms.ToTensor())\n","\n","train_size = int(20000*0.8)\n","test_size = int(20000*0.2)\n","\n","train_dataset, test_dataset = torch.utils.data.random_split(gesture_dataset, [train_size, test_size])"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":679,"status":"ok","timestamp":1643165629448,"user":{"displayName":"Bill chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03010122854624571547"},"user_tz":-480},"id":"dJl-ZNVW1_pU","outputId":"53955385-498e-40b7-9521-822a9d231240"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using cuda device\n"]}],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(f'Using {device} device')\n","\n","class Model(nn.Module):\n","  def __init__(self, dropout):\n","    super(Model, self).__init__()\n","    self.conv1 = nn.Conv2d(1,6, kernel_size=5, stride=1, padding=0)\n","    self.max_pool1 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n","    self.conv2 = nn.Conv2d(6, 16, kernel_size=5, padding=0)\n","    self.conv2_drop = nn.Dropout2d(p=dropout)\n","    self.max_pool2 = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n","\n","    self.fc1 = nn.Linear(143184, 512) # number channels * width * height\n","    self.fc2 = nn.Linear(512, 10)\n","    self.fc1_drop = nn.Dropout(p=dropout)\n","\n","  def forward(self, x):\n","    # print(x.size(0))\n","    # print(x.shape)\n","    x = torch.relu(self.max_pool1(self.conv1(x)))\n","    # print(x.shape)\n","    x = torch.relu(self.max_pool2(self.conv2_drop(self.conv2(x))))\n","    \n","    # flatten over channel, height and width\n","    # print(x.shape)\n","    x = x.view(x.size(0), x.size(1) * x.size(2) * x.size(3))\n","    \n","    x = torch.relu(self.fc1_drop(self.fc1(x)))\n","    # x = torch.softmax(self.fc2(x), dim=-1)\n","    x = torch.relu(self.fc2(x))\n","    return x\n","\n","\n","model = Model(dropout=Params.dropout).to(device)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":36,"status":"ok","timestamp":1643165629450,"user":{"displayName":"Bill chen","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03010122854624571547"},"user_tz":-480},"id":"t1tnoC5B2CFN"},"outputs":[],"source":["\n","history = {\n","  \"loss\": [],\n","  \"acc\": [],\n","  \"loss_iter\": [],\n","  \"val_loss\": [],\n","  \"val_acc\": []\n","}\n","\n","def train(dataloader, model, loss_fn, optimizer):\n","  size = len(dataloader.dataset)\n","  num_batches = len(dataloader)\n","  model.train()\n","  epoch_loss, epoch_acc = 0, 0\n","  for batch, (X, y) in enumerate(dataloader):\n","    # y = F.one_hot(y, num_classes=10).float()\n","    X, y = X.to(device), y.to(device)\n","\n","    # Compute prediction error\n","    pred = model(X)\n","    # print(pred.argmax(1))\n","    loss = loss_fn(pred, y)\n","  \n","    history[\"loss_iter\"].append(loss.item())\n","    epoch_loss += loss.item()\n","    epoch_acc += (pred.argmax(1) == y).type(torch.float).sum().item()\n","\n","    # Backpropagation\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    if batch % 100 == 0:\n","      loss, current = loss.item(), batch * len(X)\n","      print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n","  \n","  epoch_loss /= num_batches\n","  epoch_acc /= size\n","  print(epoch_loss)\n","  print(epoch_acc)\n","  history[\"loss\"].append(epoch_loss)\n","  history[\"acc\"].append(epoch_acc)\n","\n","def validate(dataloader, model, loss_fn):\n","  size = len(dataloader.dataset)\n","  num_batches = len(dataloader)\n","  model.eval()\n","  val_loss, correct = 0, 0\n","  with torch.no_grad():\n","    for X, y in dataloader:\n","      X, y = X.to(device), y.to(device)\n","      pred = model(X)\n","      val_loss += loss_fn(pred, y).item()\n","      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n","  val_loss /= num_batches\n","  correct /= size\n","  history[\"val_loss\"].append(val_loss)\n","  history[\"val_acc\"].append(correct)\n","  print(f\"Validation: \\n Accuracy: {(100*correct):>0.2f}%, Avg loss: {val_loss:>8f} \\n\")\n","\n","def test(dataloader, model, loss_fn):\n","  size = len(dataloader.dataset)\n","  num_batches = len(dataloader)\n","  model.eval()\n","  test_loss, correct = 0, 0\n","  with torch.no_grad():\n","    for X, y in dataloader:\n","      X, y = X.to(device), y.to(device)\n","      pred = model(X)\n","      test_loss += loss_fn(pred, y).item()\n","      correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n","  test_loss /= num_batches\n","  correct /= size\n","  print(f\"Test Error: \\n Accuracy: {(100*correct):>0.2f}%, Avg loss: {test_loss:>8f} \\n\")"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uqc3z65l2EaT","outputId":"98ed649b-fd9d-4377-bc60-089baa69390d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1\n","-------------------------------\n","loss: 2.297423  [    0/16000]\n"]},{"ename":"RuntimeError","evalue":"CUDA out of memory. Tried to allocate 280.00 MiB (GPU 0; 2.00 GiB total capacity; 851.07 MiB already allocated; 109.19 MiB free; 864.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[1;32m<ipython-input-7-97695aa26a3b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m   \u001b[0mtrain_dataloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mParams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m   \u001b[0mval_dataloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mParams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m   \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m   \u001b[0mvalidate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Done!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m<ipython-input-6-5658b75aa1e8>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(dataloader, model, loss_fn, optimizer)\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;31m# Backpropagation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mD:\\Programs\\Anaconda\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mD:\\Programs\\Anaconda\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    157\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 280.00 MiB (GPU 0; 2.00 GiB total capacity; 851.07 MiB already allocated; 109.19 MiB free; 864.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"]}],"source":["loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=Params.learning_rate, momentum=Params.momentum)\n","\n","\n","for t in range(Params.epochs):\n","  print(f\"Epoch {t+1}\\n-------------------------------\")\n","  train_size = int(20000*0.7)\n","  val_size = int(20000*0.1)\n","  \n","  _, val_dataset = torch.utils.data.random_split(train_dataset, [train_size, val_size])\n","\n","  train_dataloader = DataLoader(train_dataset, batch_size=Params.batch_size, shuffle=True, num_workers=0, pin_memory=True)\n","  val_dataloader = DataLoader(val_dataset, batch_size=Params.batch_size, shuffle=True, num_workers=0, pin_memory=True)\n","  train(train_dataloader, model, loss_fn, optimizer)\n","  validate(val_dataloader, model, loss_fn)\n","print(\"Done!\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pNtVSNfV7B2v"},"outputs":[],"source":["test_dataloader = DataLoader(test_dataset, batch_size=Params.batch_size, shuffle=True, num_workers=0, pin_memory=True)\n","test(test_dataloader, model, loss_fn)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CgxXEsXHiXnQ"},"outputs":[],"source":["# 保存\n","torch.save(model, 'model.pkl')\n","# 加载\n","# model = torch.load('\\model.pkl')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mOZhOxq-5ooj"},"outputs":[],"source":["# Display image and label.\n","train_features, train_labels = next(iter(train_dataloader))\n","print(f\"Feature batch shape: {train_features.size()}\")\n","print(f\"Labels batch shape: {train_labels.size()}\")\n","img = train_features[0].squeeze()\n","label = train_labels[0]\n","plt.imshow(img)\n","plt.show()\n","print(f\"Label: {label}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FrKScFaBxEV4"},"outputs":[],"source":["fig = plt.figure() # 新建一张图\n","# plt.plot(history[\"loss\"], label='training loss')\n","plt.plot(history['val_loss'], label=\"val_loss\")\n","plt.title('loss')\n","# plt.ylabel(attr)\n","plt.xlabel('epoch')\n","plt.legend()\n","plt.show()\n","\n","fig = plt.figure()\n","plt.plot(history['val_acc'], label=\"val_acc\")\n","plt.title('acc')\n","# plt.ylabel(attr)\n","plt.xlabel('epoch')\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# import torch\n","# torch.cuda.empty_cache()"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyN2eM1MUoBvesbN3htQrDVi","collapsed_sections":[],"mount_file_id":"1A-kc9nn8JQvOF-b6pt6mwVusqGLgQq0R","name":"train_torch.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":0}
